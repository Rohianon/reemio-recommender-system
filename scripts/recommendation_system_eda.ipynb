{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reemio Recommendation System - EDA Notebook\n",
        "\n",
        "**Exploratory Data Analysis** of the hybrid recommendation system with product embeddings, user preferences, and collaborative filtering.\n",
        "\n",
        "**Runtime**: ~30-45 minutes\n",
        "**Sections**: 11 comprehensive sections from data connection to final insights\n",
        "\n",
        "**Author**: Reemio Data Science Team\n",
        "**Last Updated**: 2026-01-29"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Setup & Data Connection\n",
        "\n",
        "**Goal**: Connect to PostgreSQL database and load necessary libraries\n",
        "\n",
        "This section establishes the database connection and loads all required Python libraries for data analysis and visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c9722825",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2.2.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rohiogula/Library/Python/3.13/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/rohiogula/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "# Standard imports\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from sqlalchemy import create_engine, text\n",
        "from dotenv import load_dotenv\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configure matplotlib\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Configure pandas display\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "print(\"‚úÖ All libraries loaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Database connection\n",
        "load_dotenv()\n",
        "DATABASE_URL = os.getenv(\"DATABASE_URL\")\n",
        "\n",
        "if not DATABASE_URL:\n",
        "    raise ValueError(\"DATABASE_URL not found in .env file\")\n",
        "\n",
        "# Create engine (convert to psycopg2 format for pandas)\n",
        "engine = create_engine(DATABASE_URL.replace(\"postgresql://\", \"postgresql+psycopg2://\"))\n",
        "\n",
        "# Helper function to query database\n",
        "def query_db(sql, params=None):\n",
        "    \"\"\"Execute SQL query and return pandas DataFrame\"\"\"\n",
        "    with engine.connect() as conn:\n",
        "        return pd.read_sql(text(sql), conn, params=params or {})\n",
        "\n",
        "# Test connection\n",
        "test_result = query_db(\"SELECT COUNT(*) as count FROM recommender.product_embeddings\")\n",
        "print(f\"‚úÖ Database connected successfully\")\n",
        "print(f\"Total products in database: {test_result['count'].iloc[0]:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display schema information\n",
        "schema_info = query_db(\"\"\"\n",
        "    SELECT\n",
        "        table_name,\n",
        "        pg_size_pretty(pg_total_relation_size('recommender.' || table_name)) as size\n",
        "    FROM information_schema.tables\n",
        "    WHERE table_schema = 'recommender'\n",
        "    ORDER BY table_name\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\nüìä Tables in recommender schema:\")\n",
        "display(schema_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: Product Catalog Analysis\n",
        "\n",
        "**Goal**: Understand the 3000-product catalog structure, pricing, categories, and stock levels\n",
        "\n",
        "We'll analyze:\n",
        "- Product distribution across categories\n",
        "- Price ranges and tiers\n",
        "- Stock availability\n",
        "- Active vs. inactive products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load product data\n",
        "products_df = query_db(\"\"\"\n",
        "    SELECT\n",
        "        external_product_id,\n",
        "        name,\n",
        "        category,\n",
        "        price_cents,\n",
        "        stock,\n",
        "        is_active,\n",
        "        popularity_score,\n",
        "        created_at,\n",
        "        embedding_updated_at\n",
        "    FROM recommender.product_embeddings\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Total products loaded: {len(products_df):,}\")\n",
        "products_df['price'] = products_df['price_cents'] / 100\n",
        "\n",
        "# Basic statistics\n",
        "print(f\"\\nüìä Product Overview:\")\n",
        "print(f\"  Active products: {products_df['is_active'].sum():,}\")\n",
        "print(f\"  Categories: {products_df['category'].nunique()}\")\n",
        "print(f\"  Price range: ${products_df['price'].min():.2f} - ${products_df['price'].max():.2f}\")\n",
        "print(f\"  Average price: ${products_df['price'].mean():.2f}\")\n",
        "print(f\"  Median stock: {products_df['stock'].median():.0f}\")\n",
        "\n",
        "products_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Category distribution\n",
        "category_counts = products_df['category'].value_counts().head(15)\n",
        "\n",
        "fig = px.bar(\n",
        "    x=category_counts.values,\n",
        "    y=category_counts.index,\n",
        "    orientation='h',\n",
        "    title='Top 15 Product Categories',\n",
        "    labels={'x': 'Number of Products', 'y': 'Category'},\n",
        "    color=category_counts.values,\n",
        "    color_continuous_scale='viridis'\n",
        ")\n",
        "fig.update_layout(showlegend=False, height=500)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Price distribution\n",
        "fig = make_subplots(\n",
        "    rows=1, cols=2,\n",
        "    subplot_titles=('Price Distribution', 'Price by Top 10 Categories')\n",
        ")\n",
        "\n",
        "# Histogram\n",
        "fig.add_trace(\n",
        "    go.Histogram(x=products_df['price'], nbinsx=50, name='Price'),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Box plot by category\n",
        "top_10_categories = products_df['category'].value_counts().head(10).index\n",
        "price_by_cat = products_df[products_df['category'].isin(top_10_categories)]\n",
        "\n",
        "for cat in top_10_categories:\n",
        "    cat_prices = price_by_cat[price_by_cat['category'] == cat]['price']\n",
        "    fig.add_trace(\n",
        "        go.Box(y=cat_prices, name=cat),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "fig.update_xaxes(title_text=\"Price ($)\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Frequency\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Price ($)\", row=1, col=2)\n",
        "fig.update_layout(height=500, showlegend=False, title_text=\"Product Pricing Analysis\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Price tiers\n",
        "products_df['price_tier'] = pd.cut(\n",
        "    products_df['price'],\n",
        "    bins=[0, 25, 100, 500, float('inf')],\n",
        "    labels=['Budget (<$25)', 'Mid-range ($25-$100)', 'Premium ($100-$500)', 'Luxury (>$500)']\n",
        ")\n",
        "\n",
        "tier_counts = products_df['price_tier'].value_counts()\n",
        "print(\"\\nüí∞ Price Tier Distribution:\")\n",
        "display(tier_counts.to_frame('count'))\n",
        "\n",
        "fig = px.pie(\n",
        "    values=tier_counts.values,\n",
        "    names=tier_counts.index,\n",
        "    title='Products by Price Tier',\n",
        "    hole=0.4\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stock analysis\n",
        "print(\"\\nüì¶ Stock Analysis:\")\n",
        "print(f\"  Products in stock: {(products_df['stock'] > 0).sum():,}\")\n",
        "print(f\"  Out of stock: {(products_df['stock'] == 0).sum():,}\")\n",
        "print(f\"  Average stock: {products_df['stock'].mean():.0f}\")\n",
        "print(f\"  Median stock: {products_df['stock'].median():.0f}\")\n",
        "\n",
        "fig = px.histogram(\n",
        "    products_df[products_df['stock'] < 200],  # Filter outliers for better viz\n",
        "    x='stock',\n",
        "    nbins=50,\n",
        "    title='Stock Level Distribution (capped at 200 for visibility)',\n",
        "    labels={'stock': 'Stock Level', 'count': 'Number of Products'}\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3: User Interaction Patterns\n",
        "\n",
        "**Goal**: Analyze user behavior, interaction types, and conversion funnels\n",
        "\n",
        "**Note**: This section requires interaction data. If no interactions are recorded yet, this section will show placeholder information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if interactions data exists\n",
        "interaction_count_result = query_db(\"SELECT COUNT(*) as count FROM recommender.user_interactions\")\n",
        "interaction_count = interaction_count_result['count'].iloc[0]\n",
        "\n",
        "if interaction_count == 0:\n",
        "    print(\"‚ö†Ô∏è No interaction data available yet.\")\n",
        "    print(\"\\nThis section will be populated as users interact with the system.\")\n",
        "    print(\"\\nTo generate interactions, use the API endpoints:\")\n",
        "    print(\"  POST /api/v1/interactions\")\n",
        "    print(\"\\nExample interaction types:\")\n",
        "    print(\"  - VIEW: User views a product\")\n",
        "    print(\"  - CART_ADD: User adds product to cart\")\n",
        "    print(\"  - PURCHASE: User completes purchase\")\n",
        "    print(\"  - WISHLIST_ADD: User saves product\")\n",
        "    HAS_INTERACTIONS = False\n",
        "else:\n",
        "    print(f\"‚úÖ Found {interaction_count:,} interactions to analyze\")\n",
        "    HAS_INTERACTIONS = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load interactions (if available)\n",
        "if HAS_INTERACTIONS:\n",
        "    interactions_df = query_db(\"\"\"\n",
        "        SELECT\n",
        "            interaction_type,\n",
        "            external_user_id,\n",
        "            external_product_id,\n",
        "            recommendation_context,\n",
        "            recommendation_position,\n",
        "            created_at\n",
        "        FROM recommender.user_interactions\n",
        "        ORDER BY created_at DESC\n",
        "        LIMIT 10000\n",
        "    \"\"\")\n",
        "\n",
        "    print(f\"Loaded {len(interactions_df):,} interactions\")\n",
        "\n",
        "    # Interaction type breakdown\n",
        "    type_counts = interactions_df['interaction_type'].value_counts()\n",
        "\n",
        "    fig = px.bar(\n",
        "        x=type_counts.index,\n",
        "        y=type_counts.values,\n",
        "        title='Interaction Type Distribution',\n",
        "        labels={'x': 'Interaction Type', 'y': 'Count'},\n",
        "        color=type_counts.values,\n",
        "        color_continuous_scale='blues'\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "    display(interactions_df.head(10))\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping detailed analysis - no data available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Conversion funnel analysis (if interactions exist)\n",
        "if HAS_INTERACTIONS and interaction_count > 100:\n",
        "    funnel_query = query_db(\"\"\"\n",
        "        WITH funnel AS (\n",
        "            SELECT\n",
        "                external_user_id,\n",
        "                external_product_id,\n",
        "                MAX(CASE WHEN interaction_type = 'VIEW' THEN 1 ELSE 0 END) as viewed,\n",
        "                MAX(CASE WHEN interaction_type = 'CART_ADD' THEN 1 ELSE 0 END) as added_to_cart,\n",
        "                MAX(CASE WHEN interaction_type = 'PURCHASE' THEN 1 ELSE 0 END) as purchased\n",
        "            FROM recommender.user_interactions\n",
        "            GROUP BY external_user_id, external_product_id\n",
        "        )\n",
        "        SELECT\n",
        "            SUM(viewed) as total_views,\n",
        "            SUM(added_to_cart) as total_cart_adds,\n",
        "            SUM(purchased) as total_purchases,\n",
        "            ROUND(100.0 * SUM(added_to_cart) / NULLIF(SUM(viewed), 0), 2) as view_to_cart_rate,\n",
        "            ROUND(100.0 * SUM(purchased) / NULLIF(SUM(added_to_cart), 0), 2) as cart_to_purchase_rate\n",
        "        FROM funnel\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"\\nüîÑ Conversion Funnel:\")\n",
        "    display(funnel_query)\n",
        "\n",
        "    # Funnel visualization\n",
        "    if not funnel_query.empty:\n",
        "        stages = ['Views', 'Cart Adds', 'Purchases']\n",
        "        values = [\n",
        "            int(funnel_query['total_views'].iloc[0]),\n",
        "            int(funnel_query['total_cart_adds'].iloc[0]),\n",
        "            int(funnel_query['total_purchases'].iloc[0])\n",
        "        ]\n",
        "\n",
        "        fig = go.Figure(go.Funnel(\n",
        "            y=stages,\n",
        "            x=values,\n",
        "            textinfo=\"value+percent initial\"\n",
        "        ))\n",
        "        fig.update_layout(title=\"Conversion Funnel: View ‚Üí Cart ‚Üí Purchase\")\n",
        "        fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4: Embeddings & Similarity Analysis\n",
        "\n",
        "**Goal**: Understand product embeddings (384-dimensional vectors) and semantic similarity\n",
        "\n",
        "We'll explore:\n",
        "- Embedding coverage and quality\n",
        "- Product similarity patterns\n",
        "- t-SNE visualization showing category clustering\n",
        "- Semantic relationships between products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load products with embeddings\n",
        "embeddings_df = query_db(\"\"\"\n",
        "    SELECT\n",
        "        external_product_id,\n",
        "        name,\n",
        "        category,\n",
        "        price_cents,\n",
        "        embedding\n",
        "    FROM recommender.product_embeddings\n",
        "    WHERE embedding IS NOT NULL\n",
        "    LIMIT 1000\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Loaded {len(embeddings_df):,} products with embeddings\")\n",
        "\n",
        "# Parse JSON embeddings\n",
        "embeddings_df['embedding'] = embeddings_df['embedding'].apply(json.loads)\n",
        "\n",
        "# Check embedding dimension\n",
        "sample_embedding = embeddings_df['embedding'].iloc[0]\n",
        "print(f\"Embedding dimension: {len(sample_embedding)}\")\n",
        "print(f\"Sample embedding (first 10 dims): {sample_embedding[:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find similar products for a sample\n",
        "def find_similar_products(product_idx, top_k=10):\n",
        "    \"\"\"Find top-k most similar products to the given product.\"\"\"\n",
        "    embedding_matrix = np.array(embeddings_df['embedding'].tolist())\n",
        "    query_embedding = embedding_matrix[product_idx]\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    similarities = cosine_similarity([query_embedding], embedding_matrix)[0]\n",
        "\n",
        "    # Get top-k (excluding self)\n",
        "    top_indices = np.argsort(similarities)[::-1][1:top_k+1]\n",
        "\n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        results.append({\n",
        "            'name': embeddings_df.iloc[idx]['name'],\n",
        "            'category': embeddings_df.iloc[idx]['category'],\n",
        "            'similarity': similarities[idx]\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Example: Find similar products\n",
        "sample_idx = 0\n",
        "sample_product = embeddings_df.iloc[sample_idx]\n",
        "print(f\"\\nüîç Finding products similar to: {sample_product['name']}\")\n",
        "print(f\"   Category: {sample_product['category']}\")\n",
        "\n",
        "similar_products = find_similar_products(sample_idx, top_k=10)\n",
        "display(similar_products)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# t-SNE visualization of product embeddings\n",
        "print(\"\\nüìä Generating t-SNE visualization (this may take 1-2 minutes)...\")\n",
        "\n",
        "# Sample products for faster computation\n",
        "sample_size = min(500, len(embeddings_df))\n",
        "sample_df = embeddings_df.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Create embedding matrix\n",
        "embedding_matrix = np.array(sample_df['embedding'].tolist())\n",
        "\n",
        "# Run t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "embeddings_2d = tsne.fit_transform(embedding_matrix)\n",
        "\n",
        "# Create interactive plot\n",
        "fig = px.scatter(\n",
        "    x=embeddings_2d[:, 0],\n",
        "    y=embeddings_2d[:, 1],\n",
        "    color=sample_df['category'],\n",
        "    hover_data={'name': sample_df['name'], 'category': sample_df['category']},\n",
        "    title=f\"t-SNE Visualization of Product Embeddings ({sample_size} products)\",\n",
        "    labels={'x': 't-SNE Dimension 1', 'y': 't-SNE Dimension 2', 'color': 'Category'}\n",
        ")\n",
        "fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
        "fig.update_layout(height=600)\n",
        "fig.show()\n",
        "\n",
        "print(\"\\nüí° Insight: Products of the same category should cluster together if embeddings are good!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5: User Preference & Personalization\n",
        "\n",
        "**Goal**: Analyze how user preferences are built from interaction history\n",
        "\n",
        "**Interaction Weights:**\n",
        "- PURCHASE: 5.0\n",
        "- CART_ADD: 3.0\n",
        "- WISHLIST_ADD: 2.0\n",
        "- RECOMMENDATION_CLICK: 1.5\n",
        "- VIEW: 1.0\n",
        "- CART_REMOVE: -1.0\n",
        "\n",
        "**Recency Decay:** weight √ó exp(-days / 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check user preference data\n",
        "pref_count_result = query_db(\"SELECT COUNT(*) as count FROM recommender.user_preference_embeddings\")\n",
        "pref_count = pref_count_result['count'].iloc[0]\n",
        "\n",
        "if pref_count == 0:\n",
        "    print(\"‚ö†Ô∏è No user preference embeddings available yet.\")\n",
        "    print(\"\\nUser preferences are built after users have sufficient interaction history.\")\n",
        "    print(\"To build user preferences, run:\")\n",
        "    print(\"  UserPreferenceService.update_user_preference(user_id)\")\n",
        "else:\n",
        "    print(f\"‚úÖ Found {pref_count:,} users with preference embeddings\")\n",
        "\n",
        "    # Load user preferences\n",
        "    user_prefs_df = query_db(\"\"\"\n",
        "        SELECT\n",
        "            external_user_id,\n",
        "            top_categories,\n",
        "            avg_price_min,\n",
        "            avg_price_max,\n",
        "            interaction_count,\n",
        "            last_active_at\n",
        "        FROM recommender.user_preference_embeddings\n",
        "        ORDER BY interaction_count DESC\n",
        "        LIMIT 20\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"\\nüë• Top Users by Interaction Count:\")\n",
        "    display(user_prefs_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize interaction weighting system\n",
        "import math\n",
        "\n",
        "interaction_weights = {\n",
        "    'PURCHASE': 5.0,\n",
        "    'CART_ADD': 3.0,\n",
        "    'WISHLIST_ADD': 2.0,\n",
        "    'RECOMMENDATION_CLICK': 1.5,\n",
        "    'VIEW': 1.0,\n",
        "    'CART_REMOVE': -1.0\n",
        "}\n",
        "\n",
        "# Create weight chart\n",
        "fig = px.bar(\n",
        "    x=list(interaction_weights.values()),\n",
        "    y=list(interaction_weights.keys()),\n",
        "    orientation='h',\n",
        "    title='Interaction Type Weights',\n",
        "    labels={'x': 'Weight', 'y': 'Interaction Type'},\n",
        "    color=list(interaction_weights.values()),\n",
        "    color_continuous_scale='RdYlGn'\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "# Recency decay curve\n",
        "days = np.arange(0, 91)\n",
        "decay_weights = [math.exp(-d / 30) for d in days]\n",
        "\n",
        "fig = px.line(\n",
        "    x=days,\n",
        "    y=decay_weights,\n",
        "    title='Recency Decay: weight √ó exp(-days / 30)',\n",
        "    labels={'x': 'Days Since Interaction', 'y': 'Weight Multiplier'}\n",
        ")\n",
        "fig.add_hline(y=0.5, line_dash=\"dash\", line_color=\"red\", annotation_text=\"50% weight\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 6: Hybrid Recommendation Algorithm\n",
        "\n",
        "**Goal**: Explain the 4-stage hybrid recommendation pipeline\n",
        "\n",
        "**Pipeline:**\n",
        "1. **Candidate Generation**: Content-based + Collaborative filtering (~100 candidates)\n",
        "2. **Hybrid Scoring**: Œ±√ócontent + Œ≤√ócollaborative + Œ≥√ópopularity (Œ±=0.5, Œ≤=0.3, Œ≥=0.2)\n",
        "3. **Reranking**: Cross-encoder for precise ordering (top 20)\n",
        "4. **Business Rules**: Diversity (max 3 per category), stock filtering\n",
        "\n",
        "This section demonstrates the algorithm with examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hybrid scoring demonstration\n",
        "def hybrid_score(content_score, collaborative_score, popularity_score):\n",
        "    \"\"\"Calculate hybrid score with tunable weights.\"\"\"\n",
        "    alpha, beta, gamma = 0.5, 0.3, 0.2\n",
        "    return alpha * content_score + beta * collaborative_score + gamma * popularity_score\n",
        "\n",
        "# Example candidates\n",
        "example_candidates = pd.DataFrame([\n",
        "    {'product': 'Product A', 'content': 0.95, 'collab': 0.20, 'popularity': 0.40},\n",
        "    {'product': 'Product B', 'content': 0.30, 'collab': 0.90, 'popularity': 0.60},\n",
        "    {'product': 'Product C', 'content': 0.70, 'collab': 0.70, 'popularity': 0.80},\n",
        "    {'product': 'Product D', 'content': 0.85, 'collab': 0.10, 'popularity': 0.30},\n",
        "    {'product': 'Product E', 'content': 0.40, 'collab': 0.80, 'popularity': 0.70},\n",
        "])\n",
        "\n",
        "# Calculate hybrid scores\n",
        "example_candidates['hybrid_score'] = example_candidates.apply(\n",
        "    lambda row: hybrid_score(row['content'], row['collab'], row['popularity']),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Sort by hybrid score\n",
        "example_candidates = example_candidates.sort_values('hybrid_score', ascending=False)\n",
        "\n",
        "print(\"\\nüìä Hybrid Scoring Example (Œ±=0.5, Œ≤=0.3, Œ≥=0.2):\")\n",
        "display(example_candidates)\n",
        "\n",
        "# Visualize score components\n",
        "fig = go.Figure()\n",
        "for col in ['content', 'collab', 'popularity', 'hybrid_score']:\n",
        "    fig.add_trace(go.Bar(\n",
        "        name=col.capitalize(),\n",
        "        x=example_candidates['product'],\n",
        "        y=example_candidates[col]\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Score Components by Product',\n",
        "    xaxis_title='Product',\n",
        "    yaxis_title='Score',\n",
        "    barmode='group',\n",
        "    height=500\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize how different weights affect ranking\n",
        "alphas = [0.3, 0.5, 0.7]\n",
        "results = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    beta = (1 - alpha) * 0.6  # 60% of remaining to collaborative\n",
        "    gamma = (1 - alpha) * 0.4  # 40% of remaining to popularity\n",
        "\n",
        "    scores = example_candidates.apply(\n",
        "        lambda row: alpha * row['content'] + beta * row['collab'] + gamma * row['popularity'],\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    top_product = example_candidates.iloc[scores.argmax()]['product']\n",
        "    results.append({\n",
        "        'alpha': alpha,\n",
        "        'beta': round(beta, 2),\n",
        "        'gamma': round(gamma, 2),\n",
        "        'top_product': top_product\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n‚öôÔ∏è How Weight Tuning Affects Rankings:\")\n",
        "display(results_df)\n",
        "print(\"\\nüí° Different weight combinations favor different products!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 7: Recommendation Performance Metrics\n",
        "\n",
        "**Goal**: Analyze recommendation performance by context\n",
        "\n",
        "Metrics tracked:\n",
        "- Impressions (how many times recommendations were shown)\n",
        "- Clicks (how many times users clicked)\n",
        "- Conversions (how many led to purchases)\n",
        "- CTR (Click-through rate)\n",
        "- Revenue attribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check performance data\n",
        "perf_count_result = query_db(\"SELECT COUNT(*) as count FROM recommender.recommendation_performance\")\n",
        "perf_count = perf_count_result['count'].iloc[0]\n",
        "\n",
        "if perf_count == 0:\n",
        "    print(\"‚ö†Ô∏è No recommendation performance data yet.\")\n",
        "    print(\"\\nPerformance metrics are aggregated daily as recommendations are served.\")\n",
        "else:\n",
        "    perf_df = query_db(\"\"\"\n",
        "        SELECT\n",
        "            context,\n",
        "            SUM(total_impressions) as impressions,\n",
        "            SUM(total_clicks) as clicks,\n",
        "            SUM(total_conversions) as conversions,\n",
        "            ROUND(100.0 * SUM(total_clicks) / NULLIF(SUM(total_impressions), 0), 2) as ctr,\n",
        "            ROUND(100.0 * SUM(total_conversions) / NULLIF(SUM(total_clicks), 0), 2) as conversion_rate,\n",
        "            SUM(revenue_attributed_cents) / 100 as total_revenue\n",
        "        FROM recommender.recommendation_performance\n",
        "        GROUP BY context\n",
        "        ORDER BY impressions DESC\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"\\nüìà Performance by Context:\")\n",
        "    display(perf_df)\n",
        "\n",
        "    # CTR by context\n",
        "    fig = px.bar(\n",
        "        perf_df,\n",
        "        x='context',\n",
        "        y='ctr',\n",
        "        title='Click-Through Rate by Recommendation Context',\n",
        "        labels={'ctr': 'CTR (%)', 'context': 'Context'},\n",
        "        color='ctr',\n",
        "        color_continuous_scale='blues'\n",
        "    )\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 8-11: Additional Analysis\n",
        "\n",
        "The following sections cover:\n",
        "- **Section 8**: Cart Abandonment & Email Campaigns\n",
        "- **Section 9**: Cold Start & Fallback Analysis\n",
        "- **Section 10**: Data Quality & Completeness\n",
        "- **Section 11**: Key Insights & Recommendations\n",
        "\n",
        "These sections will populate as more data becomes available in the system.\n",
        "\n",
        "To generate data:\n",
        "1. Use the API to track interactions: `POST /api/v1/interactions`\n",
        "2. Build user preferences: `UserPreferenceService.update_user_preference(user_id)`\n",
        "3. Serve recommendations: `GET /api/v1/recommendations/homepage`\n",
        "4. Track performance in the `recommendation_performance` table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ EDA Summary\n",
        "\n",
        "This notebook provided a comprehensive exploratory analysis of the Reemio recommendation system covering:\n",
        "\n",
        "1. **Data Connection** - Successfully connected to PostgreSQL with 3000+ products\n",
        "2. **Product Catalog** - Analyzed pricing, categories, and stock distribution\n",
        "3. **Embeddings** - 384-dimensional vectors with t-SNE visualization\n",
        "4. **Hybrid Algorithm** - 4-stage pipeline with content + collaborative filtering\n",
        "5. **User Preferences** - Weighted interaction system with recency decay\n",
        "\n",
        "**Next Steps:**\n",
        "- Run the recommendation API to generate more interaction data\n",
        "- Build user preference embeddings for personalization\n",
        "- Monitor recommendation performance metrics\n",
        "- Tune hybrid scoring weights (Œ±, Œ≤, Œ≥) based on A/B tests\n",
        "\n",
        "**System Status**: üü¢ Ready for recommendations"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "reemio-recommender-system",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
